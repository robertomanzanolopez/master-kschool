{"cells":[{"cell_type":"markdown","source":["# Introducción a `textblob`: otro módulo para tareas de PLN (`NLTK` + `pattern`)\n","\n","[Pablo Carballeira] Partes de este código han sido adaptadas del código de Victor Peinado https://github.com/vitojph/kschool-nlp-23\n","\n","Puedes encontrar información sobre cómo trabajar en Colab aquí (https://colab.research.google.com/notebooks/intro.ipynb)"],"metadata":{"id":"s7XRMyHrX3J5"}},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"1GB-Zxlx4MxN"},"outputs":[],"source":["# install the requirements\n","!pip install -U textblob\n","\n","import nltk\n","nltk.download(\"movie_reviews\")\n","nltk.download(\"punkt\")\n","nltk.download('brown')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"hSsY9Xhp4MxR"},"source":["[textblob](http://textblob.readthedocs.org/) es una librería de procesamiento del texto para Python que permite realizar tareas de Procesamiento del Lenguaje Natural como análisis morfológico, extracción de entidades, análisis de opinión, traducción automática, etc. "]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"bJrrxlbN4MxV"},"source":["Está construida sobre otras dos librerías muy famosas de Python: [NLTK](http://www.nltk.org/) y [pattern](https://github.com/clips/pattern/wiki). La principal ventaja de [textblob](http://textblob.readthedocs.org/) es que permite combinar el uso de las dos herramientas anteriores en un interfaz más simple.\n","\n","Vamos a apoyarnos en [este tutorial](http://textblob.readthedocs.org/en/dev/quickstart.html) para aprender a utilizar algunas de sus funcionalidades más llamativas. \n","\n","Lo primero es importar el objeto `TextBlob` que nos permite acceder a todas las herramentas que incluye."]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"eQBbUBKt4MxW"},"outputs":[],"source":["from textblob import TextBlob"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"9y8rEuZ84MxX"},"source":["Vamos a crear nuestro primer ejemplo de *textblob* a través del objeto `TextBlob`. Piensa en estos *textblobs* como una especie de cadenas de texto de Python, analizadas y enriquecidas con características de bajo nivel extraidas de forma automática "]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"7t81ph3Z4MxY"},"outputs":[],"source":["texto = \"\"\"In new lawsuits brought against the ride-sharing companies Uber and Lyft, the top prosecutors in Los Angeles \n","and San Francisco counties make an important point about the lightly regulated sharing economy. The consumers who \n","participate deserve a very clear picture of the risks they're taking.\"\"\"\n","t = TextBlob(texto)"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"e4zkm0Vm4Mxb"},"source":["## Procesando oraciones, palabras y entidades\n","\n","Podemos segmentar en oraciones y en palabras nuestra texto de ejemplo simplemente accediendo a las propiedades `.sentences` y `.words`. Imprimimos por pantalla: "]},{"cell_type":"markdown","source":["Segmentación en oraciones"],"metadata":{"id":"W6tIPwjOtnTp"}},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"JHuFlhC64Mxd"},"outputs":[],"source":["# imprimimos las oraciones\n","for sentence in t.sentences:\n","    print(sentence)\n","    print(\"-\" * 75)"]},{"cell_type":"markdown","source":["Segmentación en palabras"],"metadata":{"id":"3PP2pSY1t4mp"}},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"zAjuPqd44Mxe"},"outputs":[],"source":["# y las palabras\n","print(t.words)\n","print(texto.split())"]},{"cell_type":"markdown","source":["Análisis morfológico. Utiliza el conjunto de etiquetas de [NLTK](https://www.nltk.org/book/ch05.html)"],"metadata":{"id":"NkPo1dgWuohn"}},{"cell_type":"code","source":["# imprimimos las palabras y su etiqueta morfológica\n","for item in t.tags:\n","  print(item[0], item[1])"],"metadata":{"id":"IHmTMKl8utfW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"DECrdIZS4Mxf"},"source":["La propiedad `.noun_phrases` nos permite acceder a una lista de entidades (en este caso son son sintagmas nominales) incluídos en nuestro *textblob*. Así es como funciona."]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"ySwzb1nW4Mxg"},"outputs":[],"source":["print(\"el texto de ejemplo contiene\", len(t.noun_phrases), \"entidades\")\n","for element in t.noun_phrases:\n","    print(\"-\", element)"]},{"cell_type":"markdown","source":["Lematización en textblob. [lemmatize()](https://textblob.readthedocs.io/en/dev/_modules/textblob/blob.html#Word.lemmatize) asume por defecto que todas las palabras son nombres"],"metadata":{"id":"lTk9EEiUuL4V"}},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"CdUL1eXP4Mxh"},"outputs":[],"source":["# jugando con lemas, singulares y plurales\n","for word in t.words:\n","    if word.endswith(\"s\"):\n","        print(word, word.lemmatize(), word.singularize())\n","    else:\n","        print(word, word.lemmatize(), word.pluralize())"]},{"cell_type":"markdown","source":["Podemos utilizar las etiquetas morfológicas para hacer la lematización más inteligente\n","\n","```\n","#Verb\n","print(b.lemmatize(\"v\"))\n","#Adjective\n","print(b.lemmatize(\"a\"))\n","#Noun\n","print(b.lemmatize(\"n\"))\n","#Abverb\n","print(b.lemmatize(\"r\"))\n","```"],"metadata":{"id":"ZhdiTc6-_X2O"}},{"cell_type":"code","source":["from textblob import Word\n","w = Word(\"octopi\")\n","print(w.lemmatize())\n","w = Word(\"went\")\n","print(w.lemmatize(\"v\"))  # Pass in WordNet part of speech (verb)\n"],"metadata":{"id":"DTdrcWVkPq-L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ejercicio 1 \n","\n","Vamos a usar las etiquetas morfológicas para hacer la lematización de forma un poco más inteligente. Consideremos los siguientes casos:\n","\n","- Sustantivo singular: \"NN\" --> prularizar\n","- Sustantivo plural: \"NNS\" --> singularizar\n","- Verbos: lematizar, usando la opción adecuada"],"metadata":{"id":"CrRGI57jNH75"}},{"cell_type":"markdown","source":["Podemos utilizar el análisis morfológico (PoS) para hacer esta lematización más inteligente"],"metadata":{"id":"HmzPt8dEuRLL"}},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"9nHJwWUy4Mxi"},"outputs":[],"source":["# ???\n"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"RzaQwNVt4Mxj"},"source":["## Análisis sintático\n","\n","Aunque podemos utilizar otros analizadores, por defecto el método `.parse()` invoca al analizador morfosintáctico del módulo  `pattern.en`. Conocer bien las etiquetas requiere un esfuerzo. Puedes empezar por [aqui](https://towardsdatascience.com/chunking-in-nlp-decoded-b4a71b2b4e24)"]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"wk2iJszT4Mxk"},"outputs":[],"source":["# análisis sintáctico\n","print(t.parse())"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"uesrzvG04Mxl"},"source":["## Traducción automática\n","\n","\n","A partir de cualquier texto procesado con `TextBlob`, podemos acceder a un traductor automático de bastante calidad con el método `.translate`. Fíjate en cómo lo usamos. Es obligatorio indicar la lengua de destinto. La lengua de origen, se puede predecir a partir del texto de entrada. "]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"C5-ETG504Mxl"},"outputs":[],"source":["# de chino a inglés y español\n","oracion_zh = \"中国探月工程 亦稱嫦娥工程，是中国启动的第一个探月工程，于2003年3月1日正式启动\"\n","t_zh = TextBlob(oracion_zh)\n","print(t_zh.translate(from_lang=\"zh-CN\", to=\"en\"))\n","print(t_zh.translate(from_lang=\"zh-CN\", to=\"es\"))\n","\n","oracion_ru = \"В 1943 году была отправлена в США, где выступала в защиту британской «белой книги», после чего работала в Канаде и Индии.\"\n","t_ru = TextBlob(oracion_ru)\n","print(t_ru.translate(from_lang=\"ru\", to=\"en\"))\n","print(t_ru.translate(from_lang=\"ru\", to=\"es\"))\n","\n","print(\"--------------\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D3egW8iU4Mxn"},"outputs":[],"source":["print(\n","    TextBlob(\n","        \"\"\"المحتوى هنا ينقصه الاستشهاد بمصادر. يرجى إيراد مصادر موثوق بها\n",". أي معلومات غير موثقة يمكن التشكيك بها وإزالتها. (ديسمبر 2018)\"\"\"\n","    ).translate(to=\"es\")\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"IYNNqnwt4Mxo"},"outputs":[],"source":["t_es = TextBlob(\n","    \"La deuda pública ha marcado nuevos récords en España en el tercer trimestre\"\n",")\n","print(t_es.translate(to=\"el\"))\n","print(t_es.translate(to=\"ru\"))\n","print(t_es.translate(to=\"eu\"))\n","print(t_es.translate(to=\"fi\"))\n","print(t_es.translate(to=\"fr\"))\n","print(t_es.translate(to=\"nl\"))\n","print(t_es.translate(to=\"gl\"))\n","print(t_es.translate(to=\"ca\"))\n","print(t_es.translate(to=\"zh\"))\n","print(t_es.translate(to=\"la\"))\n","print(t_es.translate(to=\"cs\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"OSpUIXLM4Mxo"},"outputs":[],"source":["# con el slang no funciona tan bien\n","print(\"--------------\")\n","t_ita = TextBlob(\"Sono andato a Milano e mi sono divertito un bordello.\")\n","print(t_ita.translate(to=\"en\"))\n","print(t_ita.translate(to=\"es\"))"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"k809BSHS4Mxp"},"source":["## WordNet\n","\n","`textblob`, más concretamente, cualquier objeto de la clase `Word`, nos permite acceder a la información de WordNet. "]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"4kgGXpdN4Mxq"},"outputs":[],"source":["# WordNet\n","from textblob import Word\n","from textblob.wordnet import VERB\n","\n","# ¿cuántos synsets tiene \"car\"\n","word = Word(\"car\")\n","print(word.synsets)\n","\n","# dame los synsets de la palabra \"hack\" como verbo\n","print(Word(\"hack\").get_synsets(pos=VERB))\n","\n","# imprime la lista de definiciones de \"car\"\n","print(Word(\"car\").definitions)\n","\n","# recorre la jerarquía de hiperónimos\n","for s in word.synsets:\n","    print(s.hypernym_paths())"]},{"cell_type":"markdown","source":["## Resumen de textos (Text Summarization)\n","\n","Existen aproximaciones mucho más sofisticadas para esta tarea, pero podemos utilizar las herramientas básicas del análisis de texto para diseñar un método simple de resumen de texto\n","\n"],"metadata":{"id":"4CFzjAkcxsQy"}},{"cell_type":"code","source":["import random\n","\n","blob = TextBlob(\"Generative Pre-trained Transformer 3 (GPT-3) is an autoregressive language model that uses deep learning to produce human-like text. \\\n","It is the third-generation language prediction model in the GPT-n series (and the successor to GPT-2) created by OpenAI, \\\n","a San Francisco-based artificial intelligence research laboratory. GPT-3's full version has a capacity of 175 billion machine learning \\\n","parameters. GPT-3, which was introduced in May 2020, and was in beta testing as of July 2020,[3] is part of a trend in natural language \\\n","processing (NLP) systems of pre-trained language representations.\")\n","\n","nouns = list()\n","for word, tag in blob.tags:\n","  if tag == 'NN':\n","    nouns.append(word.lemmatize())\n","\n","print(nouns)\n","\n","print (\"This text is about...\")\n","for item in random.sample(nouns, 5):\n","  word = Word(item)\n","  print (word.pluralize())"],"metadata":{"id":"Pv9j4ZHkxrxS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ejercicio 2\n","\n","Podemos quedarnos con los términos más frecuentes para tener una mejor aproximación. [Pista](https://stackoverflow.com/questions/25815377/sort-list-by-frequency)"],"metadata":{"id":"-yJhLY_sHBZr"}},{"cell_type":"code","source":["# ???"],"metadata":{"id":"XNnx2IE-zlty"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"772YGasY4Mxr"},"source":["## Clasificación de textos. Análisis de opinion (Sentiment Analysis)"]},{"cell_type":"markdown","source":["Textblob proporciona clasificadores de texto para análisis de opinión ya entrenados que podemos utilizar"],"metadata":{"id":"KWaOOPLut-Og"}},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"ESbBQh5D4Mxr"},"outputs":[],"source":["# análisis de opinión\n","opinion1 = TextBlob(\"This new restaurant is really great. I had so much fun!!\")\n","print(opinion1.sentiment)\n","\n","opinion2 = TextBlob(\"I've never been in such an horrible place.\")\n","print(opinion2.sentiment)\n","\n","opinion3 = TextBlob(\"Google News to close in Spain.\")\n","print(opinion3.sentiment)\n"]},{"cell_type":"markdown","source":["El resultado de polaridad (polarity) está en el rango [-1,1] y resultado de subjetividad (subjectivity) en el rango [0,1]."],"metadata":{"id":"W0T1q-d4vnrn"}},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"MhK706Wa4Mxs"},"source":["### Ejercicio 3\n","\n","Prueba a analizar distintas oraciones en inglés, e intenta comprobar si este clasificador funciona igual que el que hemos implementado, o de forma más avanzada. Pista: juega con el orden de las palabras"]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"EZyQzZa34Mxs"},"outputs":[],"source":["# ???"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"z7k22gUx4Mxt"},"source":["`TextBlob` da acceso a [otro tipo de analizadores](https://textblob.readthedocs.io/en/dev/advanced_usage.html#sentiment-analyzers) de opinión, por ejemplo, un clasificador basado en *Naive Bayes*. Prueba qué tal funciona:"]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"dQ9_c38t4Mxu"},"outputs":[],"source":["from textblob.sentiments import NaiveBayesAnalyzer\n","\n","sentences = [\"I've never been in such an horrible place.\",'This new restaurant is really great. I had so much fun!!',\"I am not happy because I did go\"]\n","\n","for sentence in sentences:\n","    t = TextBlob(sentence, analyzer=NaiveBayesAnalyzer())\n","    print(f\"{sentence}\\nsubj: {t.sentiment}\\n\")"]},{"cell_type":"markdown","source":["Fíjate en la clasificación de la última frase"],"metadata":{"id":"vopfgSPQLoVx"}},{"cell_type":"markdown","source":["## Entrenamiento de un clasificador de texto\n","\n","Vamos a entrenar nuestro propio clasificador de texto, con un dataset muy sencillo. Primero definimos un conjunto de oraciones etiquetadas, uno de entrenamiento, y uno de test.\n","\n","Añadir otros ejemplos de clasificacion de texto, filtrado de spam, reconocimiento de autores, etc ...\n"],"metadata":{"id":"oa8aqXK53jgL"}},{"cell_type":"code","source":["train = [\n","     ('I love this sandwich.', 'pos'),\n","     ('this is an amazing place!', 'pos'),\n","     ('I feel very good about these beers.', 'pos'),\n","    ('this is my best work.', 'pos'),\n","     (\"what an awesome view\", 'pos'),\n","     ('I do not like this restaurant', 'neg'),\n","     ('I am tired of this stuff.', 'neg'),\n","     (\"I can't deal with this\", 'neg'),\n","     ('he is my sworn enemy!', 'neg'),\n","     ('my boss is horrible.', 'neg')\n","]\n","test = [\n","     ('the beer was good.', 'pos'),\n","     ('I do not enjoy my job', 'neg'),\n","     (\"I ain't feeling dandy today.\", 'neg'),\n","     (\"I feel amazing!\", 'pos'),\n","     ('Gary is a friend of mine.', 'pos'),\n","     (\"I can't believe I'm doing this.\", 'neg')\n","]"],"metadata":{"id":"_eJZRMftxxjA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Entrenamos un clasificador de texto, basado en un clasificador bayesiano, con nuestros datos de entrenamiento."],"metadata":{"id":"1NG_JZZ2x0Q1"}},{"cell_type":"code","source":["from textblob.classifiers import NaiveBayesClassifier\n","cl = NaiveBayesClassifier(train)"],"metadata":{"id":"KwoYFJ5Dx5-h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Podemos clasificar el texto usando el método `classify(text)` el clasificador que hemos entrenado."],"metadata":{"id":"YfDvDWr0ySjv"}},{"cell_type":"code","source":["cl.classify(\"Textblob is an amazing library!\")"],"metadata":{"id":"uuql9LW6ymGP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["También podemos acceder a la distribución de probabilidados de cada clase (pos,neg), utilizando el método `prob_classify(text)`\n"],"metadata":{"id":"jR1xNyKByuBx"}},{"cell_type":"code","source":["prob_dist = cl.prob_classify(\"This one's a doozy.\")\n","prob_dist.max()\n","\n","print(\"Probabilidad pos: \", round(prob_dist.prob(\"pos\"), 2))\n","print(\"Probabilidad neg: \", round(prob_dist.prob(\"neg\"), 2))"],"metadata":{"id":"3X9LuWxRyzNC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Otra posibilidad es construir un objeto textblob, asignando el clasificador que hemos creado, y utilizar el método ``clasify()` de ese objeto."],"metadata":{"id":"MXOOLzPLDjSt"}},{"cell_type":"code","source":["from textblob import TextBlob\n","blob = TextBlob(\"The beer is good. But the hangover is horrible.\", classifier=cl)\n","blob.classify()"],"metadata":{"id":"Dedf3bvcDuLD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ejercicio 4\n","\n","Fíjate que en el texto anterior, hay dos frases, y cada una tiene una opinión distinta. Utiliza las propiedades del objeto Textblob para separar automáticamente cada oración, y clasificar cada frase de forma independiente."],"metadata":{"id":"CpvIJk2KDv2p"}},{"cell_type":"code","source":["# ???"],"metadata":{"id":"m0kN4kLfDyTl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Podemos usar el conjunto de test para evaluar la precisón del clasificador"],"metadata":{"id":"G8eAHA1hD7Pn"}},{"cell_type":"code","source":["cl.accuracy(test)\n"],"metadata":{"id":"9WNYNsfrEBZ8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Interpretabilidad\n","\n","El método `show_informative_features()` permite obtener una lista de las características (unigramas) más relevantes en la clasificación."],"metadata":{"id":"Gsm7C-NEJAjj"}},{"cell_type":"code","source":["cl.show_informative_features(10)  \n"],"metadata":{"id":"9V41m5I1EGkr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fíjate que las palabras más características no tienen que ver con opiniones positivas o negativas. Esto se debe a que nuestro conjunto de entrenamiento es demasiado limitado"],"metadata":{"id":"4mqE1nO5LM3M"}},{"cell_type":"markdown","source":["Ahora vamos a entrenar el clasificador con un conjunto de datos mayor. Utilizaremos una versión limitada de un dataset común: [imdb reviews](https://www.tensorflow.org/datasets/catalog/imdb_reviews)"],"metadata":{"id":"8ILjaAPUPkBi"}},{"cell_type":"markdown","source":["Podemos entrenar el clasificador, utilizando datos recogidos en ficheros de tipo: CSV, JSON, y TSV.\n","\n","El formato de los ficheros CSV debe ser el siguiente:\n","```\n","I love this sandwich.,pos\n","This is an amazing place!,pos\n","I do not like this restaurant,neg\n","```\n","El formato de los ficheros JSOn debe ser:\n","```\n","[\n","    {\"text\": \"I love this sandwich.\", \"label\": \"pos\"},\n","    {\"text\": \"This is an amazing place!\", \"label\": \"pos\"},\n","    {\"text\": \"I do not like this restaurant\", \"label\": \"neg\"}\n","]\n","```"],"metadata":{"id":"Qu7-hUxgyJCz"}},{"cell_type":"code","source":["!mkdir data\n","!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=19-babYoT4o20ZEAoRvBmrDe5IoHMzARc' -O data/imdb.tar\n","\n","!cd data && tar xf imdb.tar\n","!rm data/imdb.tar "],"metadata":{"id":"-IWE4XiyMKJ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ??? entrena el clasificador con los datos en el fichero y fijate en las \n","# características mas discriminativas"],"metadata":{"id":"PQ3BUWKxLlHB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vemos que ha mejorado la capacidad de discriminación del clasificador. Aún así el conjunto de datos de entrenamiento (500 opiniones) que hemos utilizado es pequeño con el tamaño del dataset completo (50000 opiniones)"],"metadata":{"id":"F9V54C3rQwWH"}},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"u6F8xDi94Mxu"},"source":["## Otras curiosidades. Corrección ortográfica"]},{"cell_type":"code","execution_count":null,"metadata":{"Collapsed":"false","id":"5I8SBUcv4Mxu"},"outputs":[],"source":["#  corrección ortográfica\n","b1 = TextBlob(\"I havv goood speling!\")\n","print(b1.correct())\n","\n","b2 = TextBlob(\"Miy naem iz Jonh!\")\n","print(b2.correct())\n","\n","b3 = TextBlob(\"Boyz dont cri\")\n","print(b3.correct())\n","\n","b4 = TextBlob(\"psicological posesion achifmen comitment\")\n","print(b4.correct())"]},{"cell_type":"markdown","metadata":{"Collapsed":"false","id":"8j9d3Mqo4Mxv"},"source":["## Hasta el infinito, y más allá\n","\n","En este breve resumen solo consideramos las posibilidades que ofrece `TextBlob` por defecto. Pero si necesitas personalizar las herramientas, echa un vistazo a [la documentación avanzada](http://textblob.readthedocs.org/en/dev/advanced_usage.html#advanced). "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"09_textblob_stu.ipynb","provenance":[{"file_id":"17KmpEZtMmVql0YAjhhwq05GJIT7cjpMo","timestamp":1645615879132}],"collapsed_sections":["8j9d3Mqo4Mxv"]}},"nbformat":4,"nbformat_minor":0}