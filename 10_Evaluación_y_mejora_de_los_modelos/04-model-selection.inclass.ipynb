{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model improvement and selection\n",
    "\n",
    "\n",
    "<img src=\"https://www.python.org/static/img/python-logo.png\" alt=\"yogen\" style=\"width: 200px; float: right;\"/>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"../assets/yogen-logo.png\" alt=\"yogen\" style=\"width: 200px; float: right;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizability of our models\n",
    "\n",
    "We want to train models on known data in order to make inferences (predictions) on unknown data -> **supervised ML**\n",
    "\n",
    "How do we know how good our models are? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics for regression\n",
    "\n",
    "MSE: Mean Squared Error\n",
    "\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - h(x_i))^2$$\n",
    "\n",
    "MAE: Mean Absolute Error \n",
    "\n",
    "$$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - h(x_i)|$$\n",
    "\n",
    "MAPE: Mean Absolute Percent Error\n",
    "\n",
    "$$MAE = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{|y_i - h(x_i)|}{y_i}$$\n",
    "\n",
    "Explained Variance:\n",
    "\n",
    "\n",
    "$$explained\\_{}variance(y, \\hat{y}) = 1 - \\frac{Var\\{ y - \\hat{y}\\}}{Var\\{y\\}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/datasets/toy_dataset.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "diabetes_X, diabetes_y = diabetes['data'], diabetes['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dani/opt/anaconda3/envs/master2022/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(123.65416761001626, 143.42457577628306)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nn = MLPRegressor()\n",
    "\n",
    "\n",
    "\n",
    "mean_absolute_error(y_test, y_hat), np.sqrt(mean_squared_error(y_test, y_hat)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics in classification\n",
    "\n",
    "A first approximation could be the % of examples that we got right. This is called _accuracy_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast = datasets.load_breast_cancer()\n",
    "breast_X, breast_y = breast['data'], breast['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dani/opt/anaconda3/envs/master2022/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_X, breast_y)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_hat = lr.predict(X_test)\n",
    "probs = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9176470588235294, 0.9397590361445783, 0.9285714285714286)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "precision_score(y_test, y_hat), recall_score(y_test, y_hat), f1_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9821285140562248"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, probs[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we had very few positive examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Confusion Matrix\n",
    "\n",
    "![A confusion matrix](https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg)\n",
    "\n",
    "from https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781838555078/6/ch06lvl1sec34/confusion-matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and recall\n",
    "\n",
    "![Precision and recall](https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg)\n",
    "\n",
    "Probably best to understand them as conditional probabilities:\n",
    "\n",
    "Precision: What is the probability that an example is actually positive, given I've predicted it to be positive?\n",
    "\n",
    "Recall: What is the probability of me calling an example positive, given it is actually positive?\n",
    "\n",
    "from https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 measure\n",
    "\n",
    "A good default choice because it combines both precission and recall:\n",
    "\n",
    "$$ F_1 = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall}$$\n",
    "\n",
    "\n",
    "### $F_\\beta$\n",
    "\n",
    "F beta is a generalization of F1 that uses a (positive) weighting $\\beta$ so that recall is considered $\\beta$ times more important than precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-recall and ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb4c026cb20>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs[:, 1])\n",
    "\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The bias-variance tradeoff\n",
    "\n",
    "\n",
    "Bias: systematic error: your model doesn't quite capture the shape of the underlying function, but this doesn't change with different subsets of the input data.\n",
    "\n",
    "Variance: Your model changes a lot depending on the input data\n",
    "\n",
    "![Bias and variance](figs/bias-variance.png)\n",
    "\n",
    "from http://scott.fortmann-roe.com/docs/BiasVariance.html\n",
    "\n",
    "How can we decompose these two terms in practice?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model complexity and generalizability](https://i.stack.imgur.com/GEJIM.png)\n",
    "\n",
    "from http://scott.fortmann-roe.com/docs/BiasVariance.html\n",
    "\n",
    "What we want is generally to go into the overfitting zone to make sure we are not leaving performance on the table and then tune back our model with some regularization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9820971867007673, 0.9988280792218447)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(min_samples_leaf=5,\n",
    "                            n_estimators=100)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1]), roc_auc_score(y_train, rf.predict_proba(X_train)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-validation-test split\n",
    "\n",
    "![Train-validation-test split](https://upload.wikimedia.org/wikipedia/commons/b/bb/ML_dataset_training_validation_test_sets.png)\n",
    "\n",
    "\n",
    "from https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation\n",
    "\n",
    "![5-fold cross validation](https://www.mltut.com/wp-content/uploads/2020/05/cross-validation.png)\n",
    "\n",
    "from https://www.mltut.com/k-fold-cross-validation-in-machine-learning-how-does-k-fold-work/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Cross validation in sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98837209, 1.        , 0.95294118, 0.96470588, 0.91764706])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(X=X_train,y=y_train, estimator=rf )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros\n",
    "\n",
    "* Estimation of variance of our model\n",
    "* Better use of data\n",
    "\n",
    "Cons\n",
    "\n",
    "* Computational cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the result of a cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "\n",
    "![Under- and overfitting](https://djsaunde.files.wordpress.com/2017/07/bias-variance-tradeoff.png)\n",
    "\n",
    "from https://djsaunde.wordpress.com/2017/07/17/the-bias-variance-tradeoff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `sklearn` Pipelines for fun and profit\n",
    "\n",
    "For:\n",
    "\n",
    "1. Convenience\n",
    "\n",
    "2. Joint parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAD!\n",
    "after_a = step_a.fit_transform(train)\n",
    "after_b = step_b.fit_transform(after_a)\n",
    "after_c = step_c.fit_transform(after_b)\n",
    "classifier.fit(after_c)\n",
    "\n",
    "# NOOOOO!\n",
    "after_a = step_a.fit_transform(test)\n",
    "after_b = step_b.fit_transform(after_a)\n",
    "after_c = step_c.fit_transform(after_b)\n",
    "predictions = classifier.transform(after_c) # This classifier knows information about the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_X, breast_y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "scaled = scaler.fit_transform(X_train)\n",
    "classifier.fit(scaled, y_train)\n",
    "\n",
    "test_scaled = scaler.transform(X_test)\n",
    "y_hat = classifier.predict(test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(breast_X, breast_y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "pipeline = Pipeline(steps=[('step_1', scaler), \n",
    "                           ('step_2', classifier)])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_hat = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now the magic\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('step_1', StandardScaler()),\n",
       "                                       ('step_2', RandomForestClassifier())]),\n",
       "             param_grid={'step_2__min_samples_leaf': [1, 5, 10],\n",
       "                         'step_2__n_estimators': [10, 25, 100]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "\n",
    "grid = {'step_2__n_estimators': [10, 25, 100],\n",
    "        'step_2__min_samples_leaf': [1, 5, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, \n",
    "                           param_grid=grid,\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('step_1', StandardScaler()),\n",
       "                ('step_2', RandomForestClassifier())])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_2__min_samples_leaf': 1, 'step_2__n_estimators': 100}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_step_2__min_samples_leaf</th>\n",
       "      <th>param_step_2__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013719</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'step_2__min_samples_leaf': 1, 'step_2__n_est...</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.955349</td>\n",
       "      <td>0.028277</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998239</td>\n",
       "      <td>0.002347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024383</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>{'step_2__min_samples_leaf': 1, 'step_2__n_est...</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.964706</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.957756</td>\n",
       "      <td>0.019090</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093544</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'step_2__min_samples_leaf': 1, 'step_2__n_est...</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.960082</td>\n",
       "      <td>0.015983</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009790</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'step_2__min_samples_leaf': 5, 'step_2__n_est...</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.948290</td>\n",
       "      <td>0.027496</td>\n",
       "      <td>5</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.985337</td>\n",
       "      <td>0.982405</td>\n",
       "      <td>0.985337</td>\n",
       "      <td>0.982405</td>\n",
       "      <td>0.982391</td>\n",
       "      <td>0.003238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'step_2__min_samples_leaf': 5, 'step_2__n_est...</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.945964</td>\n",
       "      <td>0.021892</td>\n",
       "      <td>7</td>\n",
       "      <td>0.982353</td>\n",
       "      <td>0.988270</td>\n",
       "      <td>0.982405</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.988270</td>\n",
       "      <td>0.983567</td>\n",
       "      <td>0.004392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.090753</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'step_2__min_samples_leaf': 5, 'step_2__n_est...</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.953051</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>4</td>\n",
       "      <td>0.982353</td>\n",
       "      <td>0.988270</td>\n",
       "      <td>0.985337</td>\n",
       "      <td>0.982405</td>\n",
       "      <td>0.985337</td>\n",
       "      <td>0.984740</td>\n",
       "      <td>0.002206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009835</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'step_2__min_samples_leaf': 10, 'step_2__n_es...</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.934227</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>9</td>\n",
       "      <td>0.973529</td>\n",
       "      <td>0.970674</td>\n",
       "      <td>0.979472</td>\n",
       "      <td>0.953079</td>\n",
       "      <td>0.973607</td>\n",
       "      <td>0.970072</td>\n",
       "      <td>0.008966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.022451</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'step_2__min_samples_leaf': 10, 'step_2__n_es...</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>0.945992</td>\n",
       "      <td>0.024258</td>\n",
       "      <td>6</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>0.973607</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.961877</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.973007</td>\n",
       "      <td>0.005678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.086980</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'step_2__min_samples_leaf': 10, 'step_2__n_es...</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.943639</td>\n",
       "      <td>0.026241</td>\n",
       "      <td>8</td>\n",
       "      <td>0.973529</td>\n",
       "      <td>0.982405</td>\n",
       "      <td>0.973607</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.976540</td>\n",
       "      <td>0.976524</td>\n",
       "      <td>0.003227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.013719      0.003754         0.001084        0.000088   \n",
       "1       0.024383      0.000526         0.001698        0.000173   \n",
       "2       0.093544      0.000958         0.005226        0.000098   \n",
       "3       0.009790      0.000349         0.001024        0.000201   \n",
       "4       0.022991      0.000316         0.001809        0.000303   \n",
       "5       0.090753      0.002170         0.005344        0.000147   \n",
       "6       0.009835      0.000852         0.000984        0.000117   \n",
       "7       0.022451      0.000393         0.001681        0.000131   \n",
       "8       0.086980      0.000900         0.005119        0.000208   \n",
       "\n",
       "  param_step_2__min_samples_leaf param_step_2__n_estimators  \\\n",
       "0                              1                         10   \n",
       "1                              1                         25   \n",
       "2                              1                        100   \n",
       "3                              5                         10   \n",
       "4                              5                         25   \n",
       "5                              5                        100   \n",
       "6                             10                         10   \n",
       "7                             10                         25   \n",
       "8                             10                        100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'step_2__min_samples_leaf': 1, 'step_2__n_est...           0.976744   \n",
       "1  {'step_2__min_samples_leaf': 1, 'step_2__n_est...           0.953488   \n",
       "2  {'step_2__min_samples_leaf': 1, 'step_2__n_est...           0.965116   \n",
       "3  {'step_2__min_samples_leaf': 5, 'step_2__n_est...           0.976744   \n",
       "4  {'step_2__min_samples_leaf': 5, 'step_2__n_est...           0.965116   \n",
       "5  {'step_2__min_samples_leaf': 5, 'step_2__n_est...           0.953488   \n",
       "6  {'step_2__min_samples_leaf': 10, 'step_2__n_es...           0.953488   \n",
       "7  {'step_2__min_samples_leaf': 10, 'step_2__n_es...           0.953488   \n",
       "8  {'step_2__min_samples_leaf': 10, 'step_2__n_es...           0.953488   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.952941           0.952941           0.988235           0.905882   \n",
       "1           0.964706           0.952941           0.988235           0.929412   \n",
       "2           0.952941           0.952941           0.988235           0.941176   \n",
       "3           0.929412           0.952941           0.976471           0.905882   \n",
       "4           0.929412           0.941176           0.976471           0.917647   \n",
       "5           0.952941           0.941176           0.988235           0.929412   \n",
       "6           0.917647           0.929412           0.941176           0.929412   \n",
       "7           0.917647           0.941176           0.988235           0.929412   \n",
       "8           0.917647           0.941176           0.988235           0.917647   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         0.955349        0.028277                3            0.997059   \n",
       "1         0.957756        0.019090                2            1.000000   \n",
       "2         0.960082        0.015983                1            1.000000   \n",
       "3         0.948290        0.027496                5            0.976471   \n",
       "4         0.945964        0.021892                7            0.982353   \n",
       "5         0.953051        0.019687                4            0.982353   \n",
       "6         0.934227        0.012170                9            0.973529   \n",
       "7         0.945992        0.024258                6            0.976471   \n",
       "8         0.943639        0.026241                8            0.973529   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            1.000000            1.000000            0.994135   \n",
       "1            1.000000            1.000000            1.000000   \n",
       "2            1.000000            1.000000            1.000000   \n",
       "3            0.985337            0.982405            0.985337   \n",
       "4            0.988270            0.982405            0.976540   \n",
       "5            0.988270            0.985337            0.982405   \n",
       "6            0.970674            0.979472            0.953079   \n",
       "7            0.973607            0.976540            0.961877   \n",
       "8            0.982405            0.973607            0.976540   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            1.000000          0.998239         0.002347  \n",
       "1            1.000000          1.000000         0.000000  \n",
       "2            1.000000          1.000000         0.000000  \n",
       "3            0.982405          0.982391         0.003238  \n",
       "4            0.988270          0.983567         0.004392  \n",
       "5            0.985337          0.984740         0.002206  \n",
       "6            0.973607          0.970072         0.008966  \n",
       "7            0.976540          0.973007         0.005678  \n",
       "8            0.976540          0.976524         0.003227  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Train a RandomForestClassifier on the FIFA player data. Test different combinations of parameters for the RandomForestClassifier and for the preprocessing steps. A pipeline could look like this:\n",
    "\n",
    "1. StandardScaler\n",
    "2. PCA\n",
    "3. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_csv('/Users/dani/master_data/fifa/players_20.csv', index_col=0)\n",
    "players = players[players['overall'] > 75]\n",
    "numeric = players.select_dtypes('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_midfielder(player_positions):\n",
    "    \n",
    "    positions = player_positions.split(', ')\n",
    "    \n",
    "    for pos in positions:\n",
    "        if pos.endswith('M'):\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "    \n",
    "sample = 'RD'\n",
    "is_midfielder(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sofifa_id\n",
       "158023    False\n",
       "20801     False\n",
       "190871     True\n",
       "200389    False\n",
       "183277    False\n",
       "          ...  \n",
       "245326     True\n",
       "245327    False\n",
       "251691     True\n",
       "251692    False\n",
       "251698    False\n",
       "Name: player_positions, Length: 1615, dtype: bool"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = players['player_positions'].apply(is_midfielder)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 27 s, total: 1min 35s\n",
      "Wall time: 19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('pca', PCA()),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={'classifier__min_samples_leaf': [1, 5, 10],\n",
       "                         'classifier__n_estimators': [5, 25, 100],\n",
       "                         'pca__n_components': [2, 3, 5, 10, None]})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(numeric, target, random_state=1789)\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                           ('pca', PCA()),\n",
    "                           ('classifier', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                           param_grid = {'pca__n_components': [2, 3, 5, 10, None],\n",
    "                                         'classifier__n_estimators': [5, 25, 100],\n",
    "                                         'classifier__min_samples_leaf': [1, 5, 10]} )\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__min_samples_leaf': 1,\n",
       " 'classifier__n_estimators': 100,\n",
       " 'pca__n_components': None}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__min_samples_leaf</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_pca__n_components</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014792</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.773663</td>\n",
       "      <td>0.747934</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.731405</td>\n",
       "      <td>0.738204</td>\n",
       "      <td>0.021316</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013235</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.769547</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.739669</td>\n",
       "      <td>0.756198</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.765480</td>\n",
       "      <td>0.020513</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014525</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.780992</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.784502</td>\n",
       "      <td>0.016836</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015604</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.818930</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.780992</td>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.788579</td>\n",
       "      <td>0.015836</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020477</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.777064</td>\n",
       "      <td>0.016434</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.761317</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.698347</td>\n",
       "      <td>0.739669</td>\n",
       "      <td>0.744825</td>\n",
       "      <td>0.025650</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.037011</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.810700</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.780992</td>\n",
       "      <td>0.780992</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.796024</td>\n",
       "      <td>0.014136</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.044542</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.821651</td>\n",
       "      <td>0.016419</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.053539</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.819995</td>\n",
       "      <td>0.019374</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.084004</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.851240</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.816689</td>\n",
       "      <td>0.020430</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.125256</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.748971</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.743802</td>\n",
       "      <td>0.739669</td>\n",
       "      <td>0.753926</td>\n",
       "      <td>0.012608</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.127108</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.794239</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.780992</td>\n",
       "      <td>0.796864</td>\n",
       "      <td>0.013643</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.160010</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.008591</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.819168</td>\n",
       "      <td>0.013014</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.191694</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.008038</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.859504</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.826599</td>\n",
       "      <td>0.021305</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.319332</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.831276</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.839809</td>\n",
       "      <td>0.015470</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.012348</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.744856</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.739669</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.757236</td>\n",
       "      <td>0.012699</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.013695</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.756198</td>\n",
       "      <td>0.772942</td>\n",
       "      <td>0.025197</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.014088</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.800173</td>\n",
       "      <td>0.016336</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.015165</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.851240</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.812557</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.018372</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.786008</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.796045</td>\n",
       "      <td>0.020754</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.034829</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.732510</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.772122</td>\n",
       "      <td>0.024629</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.034922</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.773663</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.787790</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.041866</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.805948</td>\n",
       "      <td>0.013279</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.048922</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.831276</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.815842</td>\n",
       "      <td>0.021267</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.075866</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.794239</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.814220</td>\n",
       "      <td>0.018104</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.113442</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.780992</td>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.772115</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.116627</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.789430</td>\n",
       "      <td>0.015017</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.147195</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.008412</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.780992</td>\n",
       "      <td>0.805959</td>\n",
       "      <td>0.019237</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.173654</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.008457</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.822314</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.821634</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.282872</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.843621</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.829055</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.012181</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.720165</td>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.756198</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.761388</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.012791</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.781893</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.784478</td>\n",
       "      <td>0.017384</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.012636</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.786008</td>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.785301</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.014923</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.822460</td>\n",
       "      <td>0.012262</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.018389</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.781893</td>\n",
       "      <td>0.747934</td>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.780992</td>\n",
       "      <td>0.773734</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.033103</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.769547</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.774571</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.032606</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.757202</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.777887</td>\n",
       "      <td>0.021577</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.039115</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.773663</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.802666</td>\n",
       "      <td>0.015635</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.046807</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.815029</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.069451</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.818930</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.838843</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.820811</td>\n",
       "      <td>0.019990</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.108550</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.757202</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.772101</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.119847</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.793572</td>\n",
       "      <td>0.017557</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.137429</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.008232</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.786008</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.789256</td>\n",
       "      <td>0.807615</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.162170</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.818930</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.764463</td>\n",
       "      <td>0.814199</td>\n",
       "      <td>0.027805</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.252654</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.008809</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.814050</td>\n",
       "      <td>0.855372</td>\n",
       "      <td>0.838843</td>\n",
       "      <td>0.793388</td>\n",
       "      <td>0.825763</td>\n",
       "      <td>0.021143</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.014792      0.001925         0.002052        0.000251   \n",
       "1        0.013235      0.001227         0.002022        0.000319   \n",
       "2        0.014525      0.001349         0.002000        0.000228   \n",
       "3        0.015604      0.000655         0.002298        0.000913   \n",
       "4        0.020477      0.001304         0.002135        0.000266   \n",
       "5        0.038087      0.001007         0.003509        0.000316   \n",
       "6        0.037011      0.001505         0.003341        0.000148   \n",
       "7        0.044542      0.002292         0.003253        0.000167   \n",
       "8        0.053539      0.001302         0.003295        0.000218   \n",
       "9        0.084004      0.003257         0.003409        0.000284   \n",
       "10       0.125256      0.002223         0.008671        0.000175   \n",
       "11       0.127108      0.002633         0.009214        0.000467   \n",
       "12       0.160010      0.001646         0.008591        0.000397   \n",
       "13       0.191694      0.001181         0.008038        0.000093   \n",
       "14       0.319332      0.004415         0.008652        0.000487   \n",
       "15       0.012348      0.001027         0.001933        0.000203   \n",
       "16       0.013695      0.000937         0.002069        0.000243   \n",
       "17       0.014088      0.000936         0.001943        0.000281   \n",
       "18       0.015165      0.001175         0.001867        0.000150   \n",
       "19       0.018372      0.000613         0.002198        0.000202   \n",
       "20       0.034829      0.001311         0.003380        0.000419   \n",
       "21       0.034922      0.001261         0.003479        0.000241   \n",
       "22       0.041866      0.000894         0.003327        0.000264   \n",
       "23       0.048922      0.001264         0.003666        0.000549   \n",
       "24       0.075866      0.005528         0.003432        0.000246   \n",
       "25       0.113442      0.002029         0.008330        0.000476   \n",
       "26       0.116627      0.001692         0.008338        0.000430   \n",
       "27       0.147195      0.002637         0.008412        0.000454   \n",
       "28       0.173654      0.001248         0.008457        0.000792   \n",
       "29       0.282872      0.004964         0.008759        0.000576   \n",
       "30       0.012181      0.001166         0.002051        0.000337   \n",
       "31       0.012791      0.001129         0.002031        0.000104   \n",
       "32       0.012636      0.001281         0.002208        0.000390   \n",
       "33       0.014923      0.000725         0.002095        0.000318   \n",
       "34       0.018389      0.002576         0.002237        0.000414   \n",
       "35       0.033103      0.000785         0.003386        0.000152   \n",
       "36       0.032606      0.001052         0.003443        0.000366   \n",
       "37       0.039115      0.002003         0.003328        0.000233   \n",
       "38       0.046807      0.001864         0.005567        0.004451   \n",
       "39       0.069451      0.001506         0.003643        0.000501   \n",
       "40       0.108550      0.002548         0.008079        0.000279   \n",
       "41       0.119847      0.012071         0.008661        0.000676   \n",
       "42       0.137429      0.001877         0.008232        0.000233   \n",
       "43       0.162170      0.001547         0.008533        0.000646   \n",
       "44       0.252654      0.003933         0.008809        0.000837   \n",
       "\n",
       "   param_classifier__min_samples_leaf param_classifier__n_estimators  \\\n",
       "0                                   1                              5   \n",
       "1                                   1                              5   \n",
       "2                                   1                              5   \n",
       "3                                   1                              5   \n",
       "4                                   1                              5   \n",
       "5                                   1                             25   \n",
       "6                                   1                             25   \n",
       "7                                   1                             25   \n",
       "8                                   1                             25   \n",
       "9                                   1                             25   \n",
       "10                                  1                            100   \n",
       "11                                  1                            100   \n",
       "12                                  1                            100   \n",
       "13                                  1                            100   \n",
       "14                                  1                            100   \n",
       "15                                  5                              5   \n",
       "16                                  5                              5   \n",
       "17                                  5                              5   \n",
       "18                                  5                              5   \n",
       "19                                  5                              5   \n",
       "20                                  5                             25   \n",
       "21                                  5                             25   \n",
       "22                                  5                             25   \n",
       "23                                  5                             25   \n",
       "24                                  5                             25   \n",
       "25                                  5                            100   \n",
       "26                                  5                            100   \n",
       "27                                  5                            100   \n",
       "28                                  5                            100   \n",
       "29                                  5                            100   \n",
       "30                                 10                              5   \n",
       "31                                 10                              5   \n",
       "32                                 10                              5   \n",
       "33                                 10                              5   \n",
       "34                                 10                              5   \n",
       "35                                 10                             25   \n",
       "36                                 10                             25   \n",
       "37                                 10                             25   \n",
       "38                                 10                             25   \n",
       "39                                 10                             25   \n",
       "40                                 10                            100   \n",
       "41                                 10                            100   \n",
       "42                                 10                            100   \n",
       "43                                 10                            100   \n",
       "44                                 10                            100   \n",
       "\n",
       "   param_pca__n_components                                             params  \\\n",
       "0                        2  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "1                        3  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "2                        5  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "3                       10  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "4                     None  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "5                        2  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "6                        3  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "7                        5  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "8                       10  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "9                     None  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "10                       2  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "11                       3  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "12                       5  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "13                      10  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "14                    None  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "15                       2  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "16                       3  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "17                       5  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "18                      10  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "19                    None  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "20                       2  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "21                       3  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "22                       5  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "23                      10  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "24                    None  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "25                       2  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "26                       3  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "27                       5  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "28                      10  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "29                    None  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "30                       2  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "31                       3  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "32                       5  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "33                      10  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "34                    None  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "35                       2  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "36                       3  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "37                       5  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "38                      10  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "39                    None  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "40                       2  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "41                       3  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "42                       5  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "43                      10  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "44                    None  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.773663           0.747934           0.727273   \n",
       "1            0.769547           0.801653           0.739669   \n",
       "2            0.753086           0.797521           0.780992   \n",
       "3            0.818930           0.776860           0.780992   \n",
       "4            0.753086           0.772727           0.793388   \n",
       "5            0.761317           0.772727           0.752066   \n",
       "6            0.810700           0.814050           0.780992   \n",
       "7            0.802469           0.830579           0.847107   \n",
       "8            0.806584           0.830579           0.842975   \n",
       "9            0.806584           0.789256           0.851240   \n",
       "10           0.748971           0.772727           0.764463   \n",
       "11           0.794239           0.822314           0.793388   \n",
       "12           0.806584           0.822314           0.842975   \n",
       "13           0.814815           0.814050           0.842975   \n",
       "14           0.831276           0.822314           0.867769   \n",
       "15           0.744856           0.772727           0.764463   \n",
       "16           0.740741           0.785124           0.814050   \n",
       "17           0.790123           0.814050           0.822314   \n",
       "18           0.806584           0.809917           0.793388   \n",
       "19           0.786008           0.809917           0.805785   \n",
       "20           0.732510           0.776860           0.809917   \n",
       "21           0.773663           0.797521           0.801653   \n",
       "22           0.802469           0.809917           0.826446   \n",
       "23           0.831276           0.809917           0.826446   \n",
       "24           0.794239           0.805785           0.847107   \n",
       "25           0.740741           0.780992           0.789256   \n",
       "26           0.790123           0.797521           0.809917   \n",
       "27           0.790123           0.818182           0.834711   \n",
       "28           0.823045           0.822314           0.842975   \n",
       "29           0.843621           0.830579           0.842975   \n",
       "30           0.720165           0.789256           0.776860   \n",
       "31           0.781893           0.801653           0.793388   \n",
       "32           0.786008           0.789256           0.797521   \n",
       "33           0.823045           0.834711           0.834711   \n",
       "34           0.781893           0.747934           0.789256   \n",
       "35           0.769547           0.785124           0.789256   \n",
       "36           0.757202           0.797521           0.809917   \n",
       "37           0.773663           0.801653           0.818182   \n",
       "38           0.814815           0.818182           0.830579   \n",
       "39           0.818930           0.793388           0.847107   \n",
       "40           0.757202           0.785124           0.797521   \n",
       "41           0.777778           0.814050           0.814050   \n",
       "42           0.786008           0.809917           0.834711   \n",
       "43           0.818930           0.809917           0.830579   \n",
       "44           0.827160           0.814050           0.855372   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.710744           0.731405         0.738204        0.021316   \n",
       "1            0.756198           0.760331         0.765480        0.020513   \n",
       "2            0.793388           0.797521         0.784502        0.016836   \n",
       "3            0.789256           0.776860         0.788579        0.015836   \n",
       "4            0.797521           0.768595         0.777064        0.016434   \n",
       "5            0.698347           0.739669         0.744825        0.025650   \n",
       "6            0.780992           0.793388         0.796024        0.014136   \n",
       "7            0.805785           0.822314         0.821651        0.016419   \n",
       "8            0.830579           0.789256         0.819995        0.019374   \n",
       "9            0.814050           0.822314         0.816689        0.020430   \n",
       "10           0.743802           0.739669         0.753926        0.012608   \n",
       "11           0.793388           0.780992         0.796864        0.013643   \n",
       "12           0.809917           0.814050         0.819168        0.013014   \n",
       "13           0.859504           0.801653         0.826599        0.021305   \n",
       "14           0.842975           0.834711         0.839809        0.015470   \n",
       "15           0.739669           0.764463         0.757236        0.012699   \n",
       "16           0.768595           0.756198         0.772942        0.025197   \n",
       "17           0.776860           0.797521         0.800173        0.016336   \n",
       "18           0.851240           0.801653         0.812557        0.020126   \n",
       "19           0.760331           0.818182         0.796045        0.020754   \n",
       "20           0.772727           0.768595         0.772122        0.024629   \n",
       "21           0.801653           0.764463         0.787790        0.015638   \n",
       "22           0.805785           0.785124         0.805948        0.013279   \n",
       "23           0.834711           0.776860         0.815842        0.021267   \n",
       "24           0.818182           0.805785         0.814220        0.018104   \n",
       "25           0.776860           0.772727         0.772115        0.016612   \n",
       "26           0.785124           0.764463         0.789430        0.015017   \n",
       "27           0.805785           0.780992         0.805959        0.019237   \n",
       "28           0.834711           0.785124         0.821634        0.019809   \n",
       "29           0.826446           0.801653         0.829055        0.015271   \n",
       "30           0.756198           0.764463         0.761388        0.023460   \n",
       "31           0.793388           0.752066         0.784478        0.017384   \n",
       "32           0.785124           0.768595         0.785301        0.009430   \n",
       "33           0.801653           0.818182         0.822460        0.012262   \n",
       "34           0.768595           0.780992         0.773734        0.014507   \n",
       "35           0.760331           0.768595         0.774571        0.010870   \n",
       "36           0.764463           0.760331         0.777887        0.021577   \n",
       "37           0.814050           0.805785         0.802666        0.015635   \n",
       "38           0.826446           0.785124         0.815029        0.015978   \n",
       "39           0.838843           0.805785         0.820811        0.019990   \n",
       "40           0.760331           0.760331         0.772101        0.016216   \n",
       "41           0.789256           0.772727         0.793572        0.017557   \n",
       "42           0.818182           0.789256         0.807615        0.018194   \n",
       "43           0.847107           0.764463         0.814199        0.027805   \n",
       "44           0.838843           0.793388         0.825763        0.021143   \n",
       "\n",
       "    rank_test_score  \n",
       "0                45  \n",
       "1                40  \n",
       "2                30  \n",
       "3                27  \n",
       "4                33  \n",
       "5                44  \n",
       "6                24  \n",
       "7                 6  \n",
       "8                 9  \n",
       "9                11  \n",
       "10               43  \n",
       "11               22  \n",
       "12               10  \n",
       "13                3  \n",
       "14                1  \n",
       "15               42  \n",
       "16               36  \n",
       "17               21  \n",
       "18               16  \n",
       "19               23  \n",
       "20               37  \n",
       "21               28  \n",
       "22               19  \n",
       "23               12  \n",
       "24               14  \n",
       "25               38  \n",
       "26               26  \n",
       "27               18  \n",
       "28                7  \n",
       "29                2  \n",
       "30               41  \n",
       "31               31  \n",
       "32               29  \n",
       "33                5  \n",
       "34               35  \n",
       "35               34  \n",
       "36               32  \n",
       "37               20  \n",
       "38               13  \n",
       "39                8  \n",
       "40               39  \n",
       "41               25  \n",
       "42               17  \n",
       "43               15  \n",
       "44                4  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8277511961722488"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = grid_search.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targeting metrics other than accuracy\n",
    "\n",
    "[The scoring parameter: defining model evaluation rules](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 27.2 s, total: 1min 36s\n",
      "Wall time: 19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('pca', PCA()),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={'classifier__min_samples_leaf': [1, 5, 10],\n",
       "                         'classifier__n_estimators': [5, 25, 100],\n",
       "                         'pca__n_components': [2, 3, 5, 10, None]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(numeric, target, random_state=1789)\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                           ('pca', PCA()),\n",
    "                           ('classifier', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                           param_grid = {'pca__n_components': [2, 3, 5, 10, None],\n",
    "                                         'classifier__n_estimators': [5, 25, 100],\n",
    "                                         'classifier__min_samples_leaf': [1, 5, 10]},\n",
    "                           scoring='f1')\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__min_samples_leaf': 1,\n",
       " 'classifier__n_estimators': 100,\n",
       " 'pca__n_components': None}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__min_samples_leaf</th>\n",
       "      <th>param_classifier__n_estimators</th>\n",
       "      <th>param_pca__n_components</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015552</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.719008</td>\n",
       "      <td>0.712551</td>\n",
       "      <td>0.725257</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013164</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.763052</td>\n",
       "      <td>0.770107</td>\n",
       "      <td>0.025921</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012896</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.828685</td>\n",
       "      <td>0.807843</td>\n",
       "      <td>0.793249</td>\n",
       "      <td>0.790462</td>\n",
       "      <td>0.027311</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.776371</td>\n",
       "      <td>0.805085</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.773663</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.784895</td>\n",
       "      <td>0.019973</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021254</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.735043</td>\n",
       "      <td>0.780083</td>\n",
       "      <td>0.786611</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.686441</td>\n",
       "      <td>0.755660</td>\n",
       "      <td>0.039896</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.036726</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>0.761517</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.036456</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.792157</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.798387</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.797184</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.045601</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.827869</td>\n",
       "      <td>0.845850</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>0.817331</td>\n",
       "      <td>0.022221</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.051615</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.844622</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.821045</td>\n",
       "      <td>0.021815</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.083005</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.815126</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.825855</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.124541</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>0.765792</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.125725</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.804598</td>\n",
       "      <td>0.798387</td>\n",
       "      <td>0.807333</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.159922</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.008926</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.844622</td>\n",
       "      <td>0.817121</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.813673</td>\n",
       "      <td>0.017825</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.188740</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.008566</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.791837</td>\n",
       "      <td>0.827069</td>\n",
       "      <td>0.017806</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.313485</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 1, 'classifie...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.840500</td>\n",
       "      <td>0.014983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.012561</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.757202</td>\n",
       "      <td>0.776471</td>\n",
       "      <td>0.752941</td>\n",
       "      <td>0.751880</td>\n",
       "      <td>0.757096</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.796748</td>\n",
       "      <td>0.801556</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.768627</td>\n",
       "      <td>0.780528</td>\n",
       "      <td>0.017587</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.015612</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.004452</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>0.817814</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.808163</td>\n",
       "      <td>0.804945</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.020227</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.804781</td>\n",
       "      <td>0.801619</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.800165</td>\n",
       "      <td>0.018370</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.019499</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.813278</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.770428</td>\n",
       "      <td>0.770563</td>\n",
       "      <td>0.781184</td>\n",
       "      <td>0.023021</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.033509</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.773946</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.815094</td>\n",
       "      <td>0.770428</td>\n",
       "      <td>0.786260</td>\n",
       "      <td>0.789146</td>\n",
       "      <td>0.016618</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.033337</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.789272</td>\n",
       "      <td>0.766798</td>\n",
       "      <td>0.792701</td>\n",
       "      <td>0.029251</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.040433</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.836653</td>\n",
       "      <td>0.836502</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.814629</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.048320</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.003812</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.851406</td>\n",
       "      <td>0.818533</td>\n",
       "      <td>0.757202</td>\n",
       "      <td>0.813853</td>\n",
       "      <td>0.031060</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.073143</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.845850</td>\n",
       "      <td>0.815126</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.113022</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.008622</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.763359</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.775665</td>\n",
       "      <td>0.786260</td>\n",
       "      <td>0.783114</td>\n",
       "      <td>0.013996</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.113782</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.008676</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.798419</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.826255</td>\n",
       "      <td>0.816479</td>\n",
       "      <td>0.787149</td>\n",
       "      <td>0.807865</td>\n",
       "      <td>0.013717</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.152081</td>\n",
       "      <td>0.011701</td>\n",
       "      <td>0.008509</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.821883</td>\n",
       "      <td>0.019527</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.173063</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.856031</td>\n",
       "      <td>0.795082</td>\n",
       "      <td>0.827384</td>\n",
       "      <td>0.019577</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.277631</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 5, 'classifie...</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.832653</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.829531</td>\n",
       "      <td>0.022471</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.791209</td>\n",
       "      <td>0.798387</td>\n",
       "      <td>0.813688</td>\n",
       "      <td>0.794007</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.788689</td>\n",
       "      <td>0.022640</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.012870</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.774704</td>\n",
       "      <td>0.793774</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.768061</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.784715</td>\n",
       "      <td>0.017725</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.012233</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.781893</td>\n",
       "      <td>0.811245</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.762295</td>\n",
       "      <td>0.801520</td>\n",
       "      <td>0.025401</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.013998</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.812427</td>\n",
       "      <td>0.025306</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.017466</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>0.779923</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.786527</td>\n",
       "      <td>0.029134</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.032828</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.769811</td>\n",
       "      <td>0.809339</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.783270</td>\n",
       "      <td>0.797245</td>\n",
       "      <td>0.017554</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.033205</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.815094</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.806300</td>\n",
       "      <td>0.018165</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.039363</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.780876</td>\n",
       "      <td>0.821138</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.823970</td>\n",
       "      <td>0.787149</td>\n",
       "      <td>0.809027</td>\n",
       "      <td>0.020827</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.045348</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>0.782258</td>\n",
       "      <td>0.822389</td>\n",
       "      <td>0.025085</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.812273</td>\n",
       "      <td>0.019299</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.107987</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.008398</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.779026</td>\n",
       "      <td>0.793774</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.797048</td>\n",
       "      <td>0.783270</td>\n",
       "      <td>0.793030</td>\n",
       "      <td>0.011568</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.109652</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.801556</td>\n",
       "      <td>0.825758</td>\n",
       "      <td>0.823105</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.803196</td>\n",
       "      <td>0.018688</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.135484</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.843284</td>\n",
       "      <td>0.796813</td>\n",
       "      <td>0.820164</td>\n",
       "      <td>0.020364</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.160876</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.840816</td>\n",
       "      <td>0.862595</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.829117</td>\n",
       "      <td>0.023687</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.258722</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>0.008679</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>{'classifier__min_samples_leaf': 10, 'classifi...</td>\n",
       "      <td>0.808163</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.826562</td>\n",
       "      <td>0.027317</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.015552      0.003071         0.002650        0.000347   \n",
       "1        0.013164      0.000882         0.002584        0.000239   \n",
       "2        0.012896      0.000921         0.002443        0.000216   \n",
       "3        0.015668      0.001216         0.002553        0.000264   \n",
       "4        0.021254      0.000645         0.002597        0.000295   \n",
       "5        0.036726      0.001018         0.004038        0.000481   \n",
       "6        0.036456      0.000248         0.003914        0.000190   \n",
       "7        0.045601      0.001317         0.003583        0.000108   \n",
       "8        0.051615      0.001511         0.003721        0.000201   \n",
       "9        0.083005      0.001509         0.003990        0.000546   \n",
       "10       0.124541      0.003038         0.009274        0.000293   \n",
       "11       0.125725      0.001604         0.009216        0.000278   \n",
       "12       0.159922      0.001635         0.008926        0.000166   \n",
       "13       0.188740      0.001176         0.008566        0.000287   \n",
       "14       0.313485      0.003736         0.008825        0.000128   \n",
       "15       0.012561      0.000593         0.002303        0.000291   \n",
       "16       0.015004      0.001672         0.004876        0.004904   \n",
       "17       0.015612      0.001241         0.004452        0.003521   \n",
       "18       0.020227      0.004307         0.005773        0.005892   \n",
       "19       0.019499      0.001136         0.002510        0.000186   \n",
       "20       0.033509      0.001423         0.003623        0.000144   \n",
       "21       0.033337      0.000842         0.004086        0.000358   \n",
       "22       0.040433      0.000527         0.003905        0.000195   \n",
       "23       0.048320      0.000760         0.003812        0.000276   \n",
       "24       0.073143      0.001248         0.003826        0.000398   \n",
       "25       0.113022      0.001213         0.008622        0.000206   \n",
       "26       0.113782      0.001470         0.008676        0.000351   \n",
       "27       0.152081      0.011701         0.008509        0.000185   \n",
       "28       0.173063      0.001941         0.008659        0.000206   \n",
       "29       0.277631      0.002243         0.008941        0.000374   \n",
       "30       0.012353      0.001374         0.002489        0.000343   \n",
       "31       0.012870      0.000365         0.002278        0.000173   \n",
       "32       0.012233      0.000884         0.002514        0.000399   \n",
       "33       0.013998      0.000756         0.002307        0.000223   \n",
       "34       0.017466      0.000704         0.002515        0.000359   \n",
       "35       0.032828      0.001692         0.003947        0.000131   \n",
       "36       0.033205      0.000774         0.003535        0.000123   \n",
       "37       0.039363      0.001023         0.003742        0.000216   \n",
       "38       0.045348      0.001281         0.003749        0.000209   \n",
       "39       0.067700      0.001557         0.003819        0.000315   \n",
       "40       0.107987      0.001692         0.008398        0.000294   \n",
       "41       0.109652      0.002728         0.008584        0.000392   \n",
       "42       0.135484      0.001291         0.008440        0.000281   \n",
       "43       0.160876      0.001648         0.008471        0.000206   \n",
       "44       0.258722      0.004325         0.008679        0.000310   \n",
       "\n",
       "   param_classifier__min_samples_leaf param_classifier__n_estimators  \\\n",
       "0                                   1                              5   \n",
       "1                                   1                              5   \n",
       "2                                   1                              5   \n",
       "3                                   1                              5   \n",
       "4                                   1                              5   \n",
       "5                                   1                             25   \n",
       "6                                   1                             25   \n",
       "7                                   1                             25   \n",
       "8                                   1                             25   \n",
       "9                                   1                             25   \n",
       "10                                  1                            100   \n",
       "11                                  1                            100   \n",
       "12                                  1                            100   \n",
       "13                                  1                            100   \n",
       "14                                  1                            100   \n",
       "15                                  5                              5   \n",
       "16                                  5                              5   \n",
       "17                                  5                              5   \n",
       "18                                  5                              5   \n",
       "19                                  5                              5   \n",
       "20                                  5                             25   \n",
       "21                                  5                             25   \n",
       "22                                  5                             25   \n",
       "23                                  5                             25   \n",
       "24                                  5                             25   \n",
       "25                                  5                            100   \n",
       "26                                  5                            100   \n",
       "27                                  5                            100   \n",
       "28                                  5                            100   \n",
       "29                                  5                            100   \n",
       "30                                 10                              5   \n",
       "31                                 10                              5   \n",
       "32                                 10                              5   \n",
       "33                                 10                              5   \n",
       "34                                 10                              5   \n",
       "35                                 10                             25   \n",
       "36                                 10                             25   \n",
       "37                                 10                             25   \n",
       "38                                 10                             25   \n",
       "39                                 10                             25   \n",
       "40                                 10                            100   \n",
       "41                                 10                            100   \n",
       "42                                 10                            100   \n",
       "43                                 10                            100   \n",
       "44                                 10                            100   \n",
       "\n",
       "   param_pca__n_components                                             params  \\\n",
       "0                        2  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "1                        3  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "2                        5  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "3                       10  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "4                     None  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "5                        2  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "6                        3  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "7                        5  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "8                       10  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "9                     None  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "10                       2  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "11                       3  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "12                       5  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "13                      10  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "14                    None  {'classifier__min_samples_leaf': 1, 'classifie...   \n",
       "15                       2  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "16                       3  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "17                       5  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "18                      10  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "19                    None  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "20                       2  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "21                       3  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "22                       5  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "23                      10  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "24                    None  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "25                       2  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "26                       3  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "27                       5  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "28                      10  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "29                    None  {'classifier__min_samples_leaf': 5, 'classifie...   \n",
       "30                       2  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "31                       3  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "32                       5  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "33                      10  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "34                    None  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "35                       2  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "36                       3  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "37                       5  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "38                      10  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "39                    None  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "40                       2  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "41                       3  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "42                       5  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "43                      10  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "44                    None  {'classifier__min_samples_leaf': 10, 'classifi...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.736842           0.705882           0.752000   \n",
       "1            0.734694           0.814815           0.774194   \n",
       "2            0.750000           0.772532           0.828685   \n",
       "3            0.776371           0.805085           0.811024   \n",
       "4            0.735043           0.780083           0.786611   \n",
       "5            0.768627           0.774194           0.777778   \n",
       "6            0.792157           0.806452           0.798387   \n",
       "7            0.785124           0.827869           0.845850   \n",
       "8            0.803279           0.840816           0.844622   \n",
       "9            0.815126           0.794872           0.860759   \n",
       "10           0.765625           0.784000           0.793651   \n",
       "11           0.813008           0.817460           0.803213   \n",
       "12           0.790123           0.806584           0.844622   \n",
       "13           0.833333           0.834711           0.840816   \n",
       "14           0.838710           0.823529           0.850000   \n",
       "15           0.746988           0.757202           0.776471   \n",
       "16           0.754098           0.796748           0.801556   \n",
       "17           0.778689           0.798354           0.817814   \n",
       "18           0.818182           0.804781           0.801619   \n",
       "19           0.750000           0.813278           0.801653   \n",
       "20           0.773946           0.800000           0.815094   \n",
       "21           0.756098           0.819277           0.832061   \n",
       "22           0.801587           0.804878           0.836653   \n",
       "23           0.827309           0.814815           0.851406   \n",
       "24           0.836066           0.803419           0.870968   \n",
       "25           0.763359           0.784314           0.805970   \n",
       "26           0.798419           0.811024           0.826255   \n",
       "27           0.793651           0.824490           0.851562   \n",
       "28           0.827309           0.824490           0.834008   \n",
       "29           0.806584           0.832653           0.859438   \n",
       "30           0.791209           0.798387           0.813688   \n",
       "31           0.774704           0.793774           0.815385   \n",
       "32           0.781893           0.811245           0.825397   \n",
       "33           0.818898           0.840816           0.824490   \n",
       "34           0.770492           0.806584           0.829876   \n",
       "35           0.769811           0.809339           0.814815   \n",
       "36           0.800000           0.809524           0.815094   \n",
       "37           0.780876           0.821138           0.832000   \n",
       "38           0.816000           0.816327           0.854839   \n",
       "39           0.816327           0.783333           0.840000   \n",
       "40           0.779026           0.793774           0.812030   \n",
       "41           0.781250           0.801556           0.825758   \n",
       "42           0.796875           0.822581           0.841270   \n",
       "43           0.822581           0.829268           0.840816   \n",
       "44           0.808163           0.818182           0.867470   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.719008           0.712551         0.725257        0.016884   \n",
       "1            0.763780           0.763052         0.770107        0.025921   \n",
       "2            0.807843           0.793249         0.790462        0.027311   \n",
       "3            0.773663           0.758333         0.784895        0.019973   \n",
       "4            0.790123           0.686441         0.755660        0.039896   \n",
       "5            0.736000           0.750988         0.761517        0.015733   \n",
       "6            0.795276           0.793651         0.797184        0.005074   \n",
       "7            0.829457           0.798354         0.817331        0.022221   \n",
       "8            0.828125           0.788382         0.821045        0.021815   \n",
       "9            0.835938           0.822581         0.825855        0.021935   \n",
       "10           0.734694           0.750988         0.765792        0.021419   \n",
       "11           0.804598           0.798387         0.807333        0.006917   \n",
       "12           0.817121           0.809917         0.813673        0.017825   \n",
       "13           0.834646           0.791837         0.827069        0.017806   \n",
       "14           0.863813           0.826446         0.840500        0.014983   \n",
       "15           0.752941           0.751880         0.757096        0.010218   \n",
       "16           0.781609           0.768627         0.780528        0.017587   \n",
       "17           0.821705           0.808163         0.804945        0.015425   \n",
       "18           0.811024           0.765217         0.800165        0.018370   \n",
       "19           0.770428           0.770563         0.781184        0.023021   \n",
       "20           0.770428           0.786260         0.789146        0.016618   \n",
       "21           0.789272           0.766798         0.792701        0.029251   \n",
       "22           0.836502           0.793522         0.814629        0.018298   \n",
       "23           0.818533           0.757202         0.813853        0.031060   \n",
       "24           0.845850           0.815126         0.834286        0.023674   \n",
       "25           0.775665           0.786260         0.783114        0.013996   \n",
       "26           0.816479           0.787149         0.807865        0.013717   \n",
       "27           0.830189           0.809524         0.821883        0.019527   \n",
       "28           0.856031           0.795082         0.827384        0.019577   \n",
       "29           0.847328           0.801653         0.829531        0.022471   \n",
       "30           0.794007           0.746154         0.788689        0.022640   \n",
       "31           0.768061           0.771654         0.784715        0.017725   \n",
       "32           0.826772           0.762295         0.801520        0.025401   \n",
       "33           0.812500           0.765432         0.812427        0.025306   \n",
       "34           0.779923           0.745763         0.786527        0.029134   \n",
       "35           0.808989           0.783270         0.797245        0.017554   \n",
       "36           0.830882           0.776000         0.806300        0.018165   \n",
       "37           0.823970           0.787149         0.809027        0.020827   \n",
       "38           0.842520           0.782258         0.822389        0.025085   \n",
       "39           0.821705           0.800000         0.812273        0.019299   \n",
       "40           0.797048           0.783270         0.793030        0.011568   \n",
       "41           0.823105           0.784314         0.803196        0.018688   \n",
       "42           0.843284           0.796813         0.820164        0.020364   \n",
       "43           0.862595           0.790323         0.829117        0.023687   \n",
       "44           0.847328           0.791667         0.826562        0.027317   \n",
       "\n",
       "    rank_test_score  \n",
       "0                45  \n",
       "1                40  \n",
       "2                31  \n",
       "3                35  \n",
       "4                44  \n",
       "5                42  \n",
       "6                28  \n",
       "7                13  \n",
       "8                11  \n",
       "9                 8  \n",
       "10               41  \n",
       "11               21  \n",
       "12               16  \n",
       "13                6  \n",
       "14                1  \n",
       "15               43  \n",
       "16               39  \n",
       "17               23  \n",
       "18               26  \n",
       "19               38  \n",
       "20               32  \n",
       "21               30  \n",
       "22               14  \n",
       "23               15  \n",
       "24                2  \n",
       "25               37  \n",
       "26               20  \n",
       "27               10  \n",
       "28                5  \n",
       "29                3  \n",
       "30               33  \n",
       "31               36  \n",
       "32               25  \n",
       "33               17  \n",
       "34               34  \n",
       "35               27  \n",
       "36               22  \n",
       "37               19  \n",
       "38                9  \n",
       "39               18  \n",
       "40               29  \n",
       "41               24  \n",
       "42               12  \n",
       "43                4  \n",
       "44                7  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.829736211031175"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = grid_search.predict(X_test)\n",
    "f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional References\n",
    "\n",
    "\n",
    "[An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "\n",
    "[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)\n",
    "\n",
    "[scikit-learn cheat sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Scikit_Learn_Cheat_Sheet_Python.pdf)\n",
    "\n",
    "[Regression metrics in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)\n",
    "\n",
    "[A Simple Guide to Scikit-learn Pipelines](https://medium.com/vickdata/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf)\n",
    "\n",
    "[scikit-learn for developers](https://scikit-learn.org/stable/developers/develop.html)\n",
    "\n",
    "[Creating your own estimator in scikit-learn](http://danielhnyk.cz/creating-your-own-estimator-scikit-learn/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "405px",
    "width": "382px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
