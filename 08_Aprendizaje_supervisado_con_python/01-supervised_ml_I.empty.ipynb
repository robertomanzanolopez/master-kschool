{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supervised Machine Learning with Python I\n",
    "\n",
    "\n",
    "<img src=\"https://www.python.org/static/img/python-logo.png\" alt=\"yogen\" style=\"width: 200px; float: right;\"/>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"../assets/yogen-logo.png\" alt=\"yogen\" style=\"width: 200px; float: right;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Objectives\n",
    "\n",
    "* Learn the basic principles of Machine Learning\n",
    "\n",
    "* Get to know the `scikit-learn` library and how to use it for Machine Learning.\n",
    "\n",
    "* Understand the close relationship between ML and optimization\n",
    "\n",
    "* Learn how to do linear regression with `scikit-learn`\n",
    "\n",
    "* Learn how to evaluate the results of training a regression algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![scikit-learn cheat sheet](http://amueller.github.io/sklearn_tutorial/cheat_sheet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Regression as a model for Machine Learning\n",
    "\n",
    "Linear regression finds an $h_\\theta$ of the form:\n",
    "\n",
    "$$ h_\\theta(X) = \\theta \\cdot X = \\theta_0 + \\theta_1 \\cdot X_1 + ... + \\beta_n \\cdot X_n$$\n",
    "\n",
    "\n",
    "Notice that X is **fixed**: we have one set of data. Finding $h_\\theta(X)$ means finding the values of $\\theta$ that make $h_\\theta(X)$ most similar to y.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost (loss) function\n",
    "\n",
    "Difference between  $h_\\theta(X)$  and y\n",
    "\n",
    "$$L(\\theta) = h_\\theta(X) - y$$\n",
    "\n",
    "We need to minimize it: we need its derivative _with respect to $\\theta_i$_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML is optimization of a loss function.\n",
    "\n",
    "In the case of Linear Regression, we are lucky because we can get an analytic expression of the derivative. That means we can \"teleport\" to its minimum.\n",
    "\n",
    "In many other algorithms we can't, but we can calculate the derivative numerically at any point we want. How can we use that to find the minima?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "![Gradient Descent](http://cdn-images-1.medium.com/max/800/1*NRCWfdXa7b-ak2nBtmwRvw.png)\n",
    "\n",
    "from [primo.ai](http://primo.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Python: `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generate dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We are going to generate fake data before we dive into real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This time, rather than code our own gradient descent optimizer, we will use `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## The `Estimator` interface\n",
    "\n",
    "In scikit-learn, preprocessing, supervised and unsupervised learning algorithms share a uniform interface.\n",
    "\n",
    "Al estimators have a `.fit()` method, which takes:\n",
    "\n",
    "- X, a numpy array or scipy sparse matrix\n",
    "\n",
    "- y, in the case of supervised learning. It is a one-dimensional numpy array containing target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Once fitted, `Estimators` can either:\n",
    "\n",
    "- `.predict()` a new set of y values from an `X_test` array: classification, regression, clustering\n",
    "\n",
    "- `.transform()` an input `X_test` array: preprocessing, dimensionality reduction, feature extraction..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fitting a LinearRegression with `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Is this a good estimate of the generalization error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scoring and model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our training set error will always be an optimistic estimate of our test set error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We need to do a train, test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Metrics for regression\n",
    "\n",
    "MSE: Mean Squared Error\n",
    "\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - h(x_i))^2$$\n",
    "\n",
    "MAE: Mean Absolute Error \n",
    "\n",
    "$$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - h(x_i)|$$\n",
    "\n",
    "MAPE: Mean Absolute Percent Error\n",
    "\n",
    "$$MAE = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{|y_i - h(x_i)|}{y_i}$$\n",
    "\n",
    "Explained Variance:\n",
    "\n",
    "\n",
    "$$explained\\_{}variance(y, \\hat{y}) = 1 - \\frac{Var\\{ y - \\hat{y}\\}}{Var\\{y\\}}$$\n",
    "\n",
    "\n",
    "\n",
    "We will learn more about scoring and model selection in a later module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression algorithms in sklearn\n",
    "\n",
    "We have already met Linear regression, which is a parametric algorithm. There are, however, _non-parametric_ algorithms that do not make assumption regarding the shape of the function to be approximated.\n",
    "\n",
    "Let's try more sophisticated algorithms on our toy data and on real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with real data: \n",
    "\n",
    "```python\n",
    "diabetes = datasets.load_diabetes()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.datasets import fetch_openml\n",
    "housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizability of our models\n",
    "\n",
    "We want to train models on known data in order to make inferences (predictions) on unknown data.\n",
    "\n",
    "How do we know how good our models are? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "![Under- and overfitting](https://djsaunde.files.wordpress.com/2017/07/bias-variance-tradeoff.png)\n",
    "\n",
    "from https://djsaunde.wordpress.com/2017/07/17/the-bias-variance-tradeoff/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional References\n",
    "\n",
    "\n",
    "[An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/)\n",
    "\n",
    "[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)\n",
    "\n",
    "[scikit-learn cheat sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Scikit_Learn_Cheat_Sheet_Python.pdf)\n",
    "\n",
    "[Regression metrics in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:master2022]",
   "language": "python",
   "name": "conda-env-master2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "617px",
    "width": "426px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
